{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zv6EZpQIR7U0",
        "outputId": "a96ec7bd-c120-4fd5-dc2e-1cc72721356a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2\n",
        "import os"
      ],
      "metadata": {
        "id": "XW8fI4ImKcbJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_to_feature_vector(image, size=(32, 32)):\n",
        "\t# resize the image to a fixed size, then flatten the image into\n",
        "\t# a list of raw pixel intensities\n",
        "\treturn cv2.resize(image, size).flatten()"
      ],
      "metadata": {
        "id": "ErS_f6QNMTEw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_color_histogram(image, bins=(8, 8, 8)):\n",
        "\t# extract a 3D color histogram from the HSV color space using\n",
        "\t# the supplied number of `bins` per channel\n",
        "\thsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\thist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n",
        "\t\t[0, 180, 0, 256, 0, 256])\n",
        "\t# handle normalizing the histogram if we are using OpenCV 2.4.X\n",
        "\tif imutils.is_cv2():\n",
        "\t\thist = cv2.normalize(hist)\n",
        "\t# otherwise, perform \"in place\" normalization in OpenCV 3 (I\n",
        "\t# personally hate the way this is done\n",
        "\telse:\n",
        "\t\tcv2.normalize(hist, hist)\n",
        "\t# return the flattened histogram as the feature vector\n",
        "\treturn hist.flatten()"
      ],
      "metadata": {
        "id": "k5Yy2QlXMoTh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_sift_features(image, vector_size=32):\n",
        "    try:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        sift = cv2.SIFT_create()\n",
        "        kps, des = sift.detectAndCompute(gray, None)\n",
        "\n",
        "        # If there are no keypoints or descriptors, return zero vector\n",
        "        if des is None:\n",
        "            return np.zeros(vector_size * 128)\n",
        "\n",
        "        # Sort keypoints by response and keep the top N\n",
        "        kps = sorted(kps, key=lambda x: -x.response)\n",
        "        des = des[:vector_size]  # keep top-N descriptors\n",
        "\n",
        "        # Flatten if not enough descriptors\n",
        "        if des.shape[0] < vector_size:\n",
        "            padding = np.zeros((vector_size - des.shape[0], 128))\n",
        "            des = np.vstack((des, padding))\n",
        "\n",
        "        return des.flatten()\n",
        "\n",
        "    except cv2.error as e:\n",
        "        print(\"SIFT error:\", e)\n",
        "        return np.zeros(vector_size * 128)\n"
      ],
      "metadata": {
        "id": "WJpc-ESBUZBn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to your dataset directly\n",
        "dataset_path = \"/content/drive/MyDrive/Colab Notebooks/aps360/Lab3_Gestures_Summer\" # Replace with the actual path to your dataset\n",
        "args = {\n",
        "    \"neighbors\": 3,  # you can change k here\n",
        "    \"jobs\": -1       # use all CPU cores\n",
        "}"
      ],
      "metadata": {
        "id": "6z6zBoW0M1ic"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grab the list of images that we'll be describing\n",
        "print(\"[INFO] describing images...\")\n",
        "imagePaths = list(paths.list_images(dataset_path))\n",
        "# initialize the raw pixel intensities matrix, the features matrix,\n",
        "# and labels list\n",
        "rawImages = []\n",
        "features = []\n",
        "siftFeatures = []\n",
        "combinedFeatures = []\n",
        "labels = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJdFOEY_M2SR",
        "outputId": "7f82173e-8489-48a0-e271-1a2698463ce8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] describing images...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loop over the input images\n",
        "for (i, imagePath) in enumerate(imagePaths):\n",
        "    image = cv2.imread(imagePath)\n",
        "    label = imagePath.split(os.path.sep)[-2].strip()\n",
        "\n",
        "    # Extract features\n",
        "    pixels = image_to_feature_vector(image)\n",
        "    hist = extract_color_histogram(image)\n",
        "    sift = extract_sift_features(image)\n",
        "    combined = np.hstack([hist, sift])\n",
        "\n",
        "    # Append to lists\n",
        "    rawImages.append(pixels)\n",
        "    features.append(hist)\n",
        "    siftFeatures.append(sift)\n",
        "    combinedFeatures.append(combined)\n",
        "    labels.append(label)\n",
        "\n",
        "    if i > 0 and i % 500 == 0:\n",
        "        print(f\"[INFO] processed {i}/{len(imagePaths)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un-HqboMNmR3",
        "outputId": "6d887dc4-893d-4b2c-df34-8c31fb2f0174"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] processed 500/2219\n",
            "[INFO] processed 1000/2219\n",
            "[INFO] processed 1500/2219\n",
            "[INFO] processed 2000/2219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show some information on the memory consumed by the raw images\n",
        "# matrix and features matrix\n",
        "rawImages = np.array(rawImages)\n",
        "features = np.array(features)\n",
        "siftFeatures = np.array(siftFeatures)\n",
        "combinedFeatures = np.array(combinedFeatures)\n",
        "labels = np.array(labels)\n",
        "print(\"[INFO] Data shapes:\")\n",
        "print(f\"Raw Pixels: {rawImages.shape}\")\n",
        "print(f\"Color Histograms: {features.shape}\")\n",
        "print(f\"SIFT: {siftFeatures.shape}\")\n",
        "print(f\"Combined: {combinedFeatures.shape}\")\n",
        "print(f\"Labels: {labels.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcMy2rdwO0FT",
        "outputId": "3724efc2-03c1-4740-f04c-cb32832e9e56"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Data shapes:\n",
            "Raw Pixels: (2219, 3072)\n",
            "Color Histograms: (2219, 512)\n",
            "SIFT: (2219, 4096)\n",
            "Combined: (2219, 4608)\n",
            "Labels: (2219,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# partition the data into training and testing splits, using 75%\n",
        "# of the data for training and the remaining 25% for testing\n",
        "(trainRI, testRI, trainRL, testRL) = train_test_split(rawImages, labels, test_size=0.25, random_state=42)\n",
        "(trainHist, testHist, trainHistLabels, testHistLabels) = train_test_split(features, labels, test_size=0.25, random_state=42)\n",
        "(trainSIFT, testSIFT, trainSIFTLabels, testSIFTLabels) = train_test_split(siftFeatures, labels, test_size=0.25, random_state=42)\n",
        "(trainCombo, testCombo, trainComboLabels, testComboLabels) = train_test_split(combinedFeatures, labels, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "jdysnIpYQsY4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(name, trainX, testX, trainY, testY):\n",
        "    print(f\"[INFO] evaluating {name} accuracy...\")\n",
        "    model = KNeighborsClassifier(n_neighbors=args[\"neighbors\"], n_jobs=args[\"jobs\"])\n",
        "    model.fit(trainX, trainY)\n",
        "    acc = model.score(testX, testY)\n",
        "    print(f\"[INFO] {name} accuracy: {acc * 100:.2f}%\\n\")"
      ],
      "metadata": {
        "id": "kiEROHfuRL3Z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Normalize each feature set separately\n",
        "scaler_raw = StandardScaler().fit(trainRI)\n",
        "trainRI_norm = scaler_raw.transform(trainRI)\n",
        "testRI_norm = scaler_raw.transform(testRI)\n",
        "\n",
        "scaler_hist = StandardScaler().fit(trainHist)\n",
        "trainHist_norm = scaler_hist.transform(trainHist)\n",
        "testHist_norm = scaler_hist.transform(testHist)\n",
        "\n",
        "scaler_sift = StandardScaler().fit(trainSIFT)\n",
        "trainSIFT_norm = scaler_sift.transform(trainSIFT)\n",
        "testSIFT_norm = scaler_sift.transform(testSIFT)\n",
        "\n",
        "scaler_combo = StandardScaler().fit(trainCombo)\n",
        "trainCombo_norm = scaler_combo.transform(trainCombo)\n",
        "testCombo_norm = scaler_combo.transform(testCombo)\n",
        "\n",
        "# Then use the normalized data in evaluate_model:\n",
        "evaluate_model(\"Raw Pixel\", trainRI_norm, testRI_norm, trainRL, testRL)\n",
        "evaluate_model(\"Color Histogram\", trainHist_norm, testHist_norm, trainHistLabels, testHistLabels)\n",
        "evaluate_model(\"SIFT\", trainSIFT_norm, testSIFT_norm, trainSIFTLabels, testSIFTLabels)\n",
        "evaluate_model(\"Color Histogram + SIFT\", trainCombo_norm, testCombo_norm, trainComboLabels, testComboLabels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2itA8kqYRN9g",
        "outputId": "2ef13edd-e879-4d8e-a8d8-5ef61aee53e5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] evaluating Raw Pixel accuracy...\n",
            "[INFO] Raw Pixel accuracy: 53.69%\n",
            "\n",
            "[INFO] evaluating Color Histogram accuracy...\n",
            "[INFO] Color Histogram accuracy: 32.97%\n",
            "\n",
            "[INFO] evaluating SIFT accuracy...\n",
            "[INFO] SIFT accuracy: 14.77%\n",
            "\n",
            "[INFO] evaluating Color Histogram + SIFT accuracy...\n",
            "[INFO] Color Histogram + SIFT accuracy: 17.84%\n",
            "\n"
          ]
        }
      ]
    }
  ]
}